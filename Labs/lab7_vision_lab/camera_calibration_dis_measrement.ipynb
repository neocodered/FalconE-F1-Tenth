{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining camera Intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def calibrate_chessboard_images(image_folder, pattern_size=(6, 8), square_size=25.0):\n",
    "    \"\"\"\n",
    "    Calibrate camera given a set of chessboard images.\n",
    "    \n",
    "    :param image_folder: Folder containing chessboard images.\n",
    "    :param pattern_size: Tuple of (number_of_corners_along_width, number_of_corners_along_height).\n",
    "    :param square_size: Physical size of each chessboard square (in cm, mm, or any consistent unit).\n",
    "    :return: camera_matrix, dist_coeffs, rvecs, tvecs, error\n",
    "    \"\"\"\n",
    "\n",
    "    # Termination criteria for corner refinement\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare 3D object points for a single chessboard\n",
    "    objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "    # Scale object points by the size of each square\n",
    "    objp *= square_size\n",
    "\n",
    "    # Arrays to store object points and image points from all images\n",
    "    objpoints = []  # 3D points in real-world space\n",
    "    imgpoints = []  # 2D points in image plane\n",
    "\n",
    "    images = glob.glob(os.path.join(image_folder, '*_Color.png'))  # or '*.png', etc.\n",
    "    if not images:\n",
    "        print(f\"No images found in {image_folder}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Track image shape (width, height)\n",
    "    image_shape = None\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        # If the image can't be read, skip it\n",
    "        if img is None:\n",
    "            print(f\"Could not read {fname}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # We set image_shape if not already set\n",
    "        if image_shape is None:\n",
    "            # OpenCV calibrateCamera expects (width, height) order\n",
    "            image_shape = gray.shape[::-1]\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "        if ret:\n",
    "            # Refine corner positions to sub-pixel accuracy\n",
    "            corners_refined = cv2.cornerSubPix(\n",
    "                gray, corners, (11, 11), (-1, -1), criteria\n",
    "            )\n",
    "\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners_refined)\n",
    "\n",
    "            # Draw corners (optional for visualization)\n",
    "            cv2.drawChessboardCorners(img, pattern_size, corners_refined, ret)\n",
    "            cv2.imshow('Chessboard Corners', img)\n",
    "            cv2.waitKey()  # Show each result briefly\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If we never detected corners, there is nothing to calibrate\n",
    "    if not objpoints or not imgpoints:\n",
    "        print(\"No corners were detected in any image. Calibration aborted.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Perform camera calibration\n",
    "    ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints,\n",
    "        imgpoints,\n",
    "        image_shape,  # Using stored shape\n",
    "        None,\n",
    "        None\n",
    "    )\n",
    "\n",
    "    # Compute overall reprojection error\n",
    "    total_error = 0\n",
    "    for i in range(len(objpoints)):\n",
    "        imgpoints2, _ = cv2.projectPoints(\n",
    "            objpoints[i], rvecs[i], tvecs[i], camera_matrix, dist_coeffs\n",
    "        )\n",
    "        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "        total_error += error\n",
    "\n",
    "    mean_error = total_error / len(objpoints)\n",
    "\n",
    "    print(\"Camera matrix:\\n\", camera_matrix)\n",
    "    print(\"Distortion coefficients:\", dist_coeffs.ravel())\n",
    "    print(\"Mean reprojection error:\", mean_error)\n",
    "\n",
    "    return camera_matrix, dist_coeffs, rvecs, tvecs, mean_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadil\\Desktop\\FalconE-F1-Tenth\\Labs\\lab7_vision_lab\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) # print current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix:\n",
      " [[694.71543755   0.         449.37542153]\n",
      " [  0.         695.54962013 258.64702588]\n",
      " [  0.           0.           1.        ]]\n",
      "Distortion coefficients: [ 0.14754686  0.19250433 -0.0091839  -0.01212939 -1.70648829]\n",
      "Mean reprojection error: 0.08230803535365025\n"
     ]
    }
   ],
   "source": [
    "folder = \"Resources\\calibration\"\n",
    "camera_matrix, dist_coeffs, rvecs, tvecs, mean_error = calibrate_chessboard_images(folder, pattern_size=(6, 8), square_size=25.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Suppose you have these from prior calibration:\n",
    "# (Typical shape: fx, 0, cx; 0, fy, cy; 0, 0, 1)\n",
    "camera_matrix = camera_matrix\n",
    "\n",
    "# If you have lens distortion, fill this in. Otherwise, assume zero:\n",
    "dist_coeffs = dist_coeffs  # [k1, k2, p1, p2, k3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the base of the cone, then press ESC.\n",
      "Clicked pixel: (u=662, v=493)\n",
      "Pixel for known 40cm cone is: (662, 493)\n"
     ]
    }
   ],
   "source": [
    "def click_and_get_pixel(image_path):\n",
    "    \"\"\"\n",
    "    Utility function that shows an image and lets you click exactly one pixel.\n",
    "    Returns (u, v) of the clicked point.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise IOError(f\"Cannot read {image_path}\")\n",
    "\n",
    "    clicked_point = []\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            clicked_point[:] = [x, y]  # store in outer list\n",
    "            print(f\"Clicked pixel: (u={x}, v={y})\")\n",
    "\n",
    "    cv2.namedWindow(\"ClickCone\")\n",
    "    cv2.setMouseCallback(\"ClickCone\", mouse_callback)\n",
    "\n",
    "    print(\"Click on the base of the cone, then press ESC.\")\n",
    "    while True:\n",
    "        cv2.imshow(\"ClickCone\", img)\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == 27:  # ESC to break\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(clicked_point) == 2:\n",
    "        return (clicked_point[0], clicked_point[1])  # (u, v)\n",
    "    else:\n",
    "        raise ValueError(\"No click registered.\")\n",
    "\n",
    "# Example usage for known 40cm cone\n",
    "u_40, v_40 = click_and_get_pixel(\"Resources/resource/cone_x40cm.png\")\n",
    "print(\"Pixel for known 40cm cone is:\", (u_40, v_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx camera mounting height: 13.5 cm\n"
     ]
    }
   ],
   "source": [
    "def estimate_camera_height(u_40, v_40, x_car=0.40, camera_matrix=None):\n",
    "    \"\"\"\n",
    "    Estimate camera height H by assuming:\n",
    "      - The cone at x_car=0.40m is lying on the ground plane z=0.\n",
    "      - The camera is pointed horizontally (no pitch).\n",
    "      - The camera is at some height H above ground.\n",
    "      - The cone is directly along the optical axis (i.e. no lateral offset).\n",
    "    Returns approximate H in meters.\n",
    "    \n",
    "    In reality, you need a more robust geometry solution or multiple points.\n",
    "    \"\"\"\n",
    "    fx = camera_matrix[0,0]\n",
    "    cx = camera_matrix[0,2]\n",
    "    # We'll just do a naive \"similar triangles\" approach:\n",
    "    #\n",
    "    # If the optical axis is horizontal, the ground at distance x_car\n",
    "    # would appear below the horizon by some amount in image coordinates.\n",
    "    # The difference (v_40 - cy) is due to camera height H.\n",
    "    #\n",
    "    # For small angles, H ~ x_car * ( (v_40 - cy) / fx ).\n",
    "    #\n",
    "    # This is not physically perfect. But let's do a rough approximation:\n",
    "    v_offset = (v_40 - camera_matrix[1,2])  # how many pixels below center\n",
    "    # We'll say \"tan(theta) = H / x_car\" ~ v_offset / fx\n",
    "    # => H = x_car * (v_offset / fx)\n",
    "    # The sign depends on your coordinate system. We'll assume downward is positive v.\n",
    "    H = x_car * (abs(v_offset) / fx)\n",
    "\n",
    "    return H\n",
    "\n",
    "H_approx = estimate_camera_height(\n",
    "    u_40, v_40, \n",
    "    x_car=0.40,\n",
    "    camera_matrix=camera_matrix\n",
    ")\n",
    "print(f\"Approx camera mounting height: {H_approx*100:.1f} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_car(u, v, camera_matrix, H):\n",
    "    \"\"\"\n",
    "    Map pixel (u,v) to (x_car, y_car), assuming:\n",
    "      - Ground plane is z=0 in 'car' coords.\n",
    "      - Camera is at (0, H, 0).\n",
    "      - Optical axis is horizontal (no tilt).\n",
    "      - +x_car is forward, +y_car is to the left or right (depends on your convention).\n",
    "    Returns (x_car, y_car).\n",
    "    \n",
    "    This is a simplistic pinhole-based approach. Real labs often use a homography \n",
    "    or solvePnP with multiple reference points.\n",
    "    \"\"\"\n",
    "    fx = camera_matrix[0,0]\n",
    "    fy = camera_matrix[1,1]\n",
    "    cx = camera_matrix[0,2]\n",
    "    cy = camera_matrix[1,2]\n",
    "\n",
    "    # In camera coordinates (assuming no tilt):\n",
    "    # Let's define Z_c = X_car, X_c = Y_car, Y_c = ??? depends on your convention.\n",
    "    #\n",
    "    # For a point on the ground, let's do a quick ratio approach:\n",
    "    #    (v - cy) / fy ~ (Y_c / Z_c)\n",
    "    #    (u - cx) / fx ~ (X_c / Z_c)\n",
    "    #\n",
    "    # But we also know the camera is at height H, so the ground is -H below it\n",
    "    # in Y_c if the camera's +Y is downward. \n",
    "    #\n",
    "    # A simpler approach is to say the distance from the camera is:\n",
    "    #   X_car = H * (fx / (v - cy))   if the point is purely in front, ignoring sideways offset\n",
    "    #\n",
    "    # That is borrowed from the typical \"flat-world assumption\" for a downward-facing camera,\n",
    "    # or you invert your geometry. \n",
    "    #\n",
    "    # We also want y_car if there's a horizontal offset. \n",
    "    # Typically: y_car = (u - cx)/fx * x_car. \n",
    "    # \n",
    "    # The sign of y_car depends on whether you define right or left as positive.\n",
    "\n",
    "    # For demonstration, let's define:\n",
    "    dy = (u - cx)  # horizontal pixel offset\n",
    "    dv = (v - cy)  # vertical pixel offset\n",
    "\n",
    "    # approximate forward distance:\n",
    "    x_car = H * (fy / abs(dv)) if dv != 0 else 9999  # big fallback if dv=0\n",
    "    # approximate lateral distance:\n",
    "    y_car = x_car * (dy / fx)\n",
    "\n",
    "    # Depending on your sign conventions, you might invert y_car or x_car\n",
    "    return (x_car, y_car)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the base of the cone, then press ESC.\n",
      "Clicked pixel: (u=596, v=414)\n",
      "Pixel for unknown cone is: (596, 414)\n",
      "Using camera height H ~ 0.135 m from cone_x40cm.png...\n",
      "Unknown cone is at x_car=0.604 m, y_car=0.128 m\n"
     ]
    }
   ],
   "source": [
    "def measure_unknown_cone_distance():\n",
    "    # 1) Click the base in cone_unknown.png\n",
    "    u_unknown, v_unknown = click_and_get_pixel(\"Resources/resource/cone_unknown.png\")\n",
    "    print(\"Pixel for unknown cone is:\", (u_unknown, v_unknown))\n",
    "\n",
    "    # 2) Use the previously computed height\n",
    "    print(f\"Using camera height H ~ {H_approx:.3f} m from cone_x40cm.png...\")\n",
    "\n",
    "    # 3) Convert that pixel to (x_car, y_car)\n",
    "    x_car_unknown, y_car_unknown = pixel_to_car(\n",
    "        u_unknown, \n",
    "        v_unknown,\n",
    "        camera_matrix, \n",
    "        H_approx  # from earlier\n",
    "    )\n",
    "    print(f\"Unknown cone is at x_car={x_car_unknown:.3f} m, y_car={y_car_unknown:.3f} m\")\n",
    "\n",
    "measure_unknown_cone_distance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Edith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
